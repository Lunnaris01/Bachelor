\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Reinforcement Learning Framework}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Elements of Reinforcement Learning}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Markov Decision Process}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{Deep Reinforcement Learning}{section.2}% 5
\BOOKMARK [1][-]{section.3}{Actor-Critic Methods}{}% 6
\BOOKMARK [2][-]{subsection.3.1}{TD-Learning}{section.3}% 7
\BOOKMARK [2][-]{subsection.3.2}{Critic-Only Methods}{section.3}% 8
\BOOKMARK [2][-]{subsection.3.3}{Actor-Only Methods}{section.3}% 9
\BOOKMARK [2][-]{subsection.3.4}{Actor-Critic Methods}{section.3}% 10
\BOOKMARK [2][-]{subsection.3.5}{Asynchronous Advantage Actor Critic \(A3C\)}{section.3}% 11
\BOOKMARK [1][-]{section.4}{Off-Policy Learning}{}% 12
\BOOKMARK [2][-]{subsection.4.1}{Importance Sampling \(IS\)}{section.4}% 13
\BOOKMARK [2][-]{subsection.4.2}{Tree-backup, TB\(\)}{section.4}% 14
\BOOKMARK [2][-]{subsection.4.3}{Retrace\(\)}{section.4}% 15
\BOOKMARK [1][-]{section.5}{Actor-Critic with Experience Replay \(ACER\)}{}% 16
\BOOKMARK [1][-]{section*.4}{References}{}% 17
\BOOKMARK [1][-]{section*.5}{List of Figures}{}% 18
\BOOKMARK [1][-]{section*.6}{List of Tables}{}% 19
