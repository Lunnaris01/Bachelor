\section{Introduction}\raggedbottom 
\citet{Sut98} describes the reinforcement learning  task as "learning what to do".
Acting optimal within an unknown environment can be very difficult.
The field within machine learning adressing this problem is called reinforcement learning.

The reinforcement problem consist of an \textit{agent} taking \textit{actions} within some sort of \textit{environment}.
By interacting with the \textit{environment} the \textit{agent} receives \textit{rewards}.

The goal of reinforcement learning is to create fast and reliable learning algorithms for the \textit{agent} to gain the maximum \textit{reward}

Environments can range from simple tasks, like balancing a pole to very complex and demanding tasks where \textit{environment states} are given as pixels, continuous control problems or real life robotic tasks.
This thesis will work with the Atari 2600 environments offered by OpenAI \citep{openaigym}

By combining deep learning techniques \citep{Hinton504} with reinforcemen learning, the problems posed by most of the Atari games can easily be solved.

However complex environment like the Atari 2600 games can often be costly to simulate.

ACER \citep{ACER} provides a sample efficient learning agent. This work aims at implementing and evaluating the Algorithm

This thesis will provide a short overview for important concepts of reinforcement learning

To lay out the foundation for ACER, policy gradient, specifically Actor-Critic methods and the Advantage Actor Critic(A3C) - Algorithm \citep{A3C} are looked upon, followed by an introduction to some approaches of Off-Policy learning.

Finally the ACER- Algorithm is presented, implemented and evaluated.



\pagebreak